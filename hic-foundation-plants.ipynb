{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2f7472c2-6511-4fc6-a69b-1a7ed1d84398",
      "metadata": {},
      "source": [
        "HiCFoundation Resolution Enhancement Pipeline\n",
        "This document provides a complete pipeline for Hi-C resolution enhancement using HiCFoundation, including data preprocessing, pre-training, fine-tuning, and inference.\n",
        "Table of Contents\n",
        "\n",
        "1. Environment Setup\n",
        "2. Data Preprocessing\n",
        "3. Submatrix Generation\n",
        "4. Pre-training\n",
        "5. Fine-tuning Preparation\n",
        "6. Fine-tuning\n",
        "7. Inference\n",
        "8. Visualization and Evaluation\n",
        "\n",
        "Environment Setup:\n",
        "Install Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "105fd092-052c-4d49-98cb-f07798c8fd11",
      "metadata": {},
      "source": [
        "Install pip: https://pip.pypa.io/en/stable/installation/\n",
        "\n",
        "\n",
        "Install pytorch: Install pytorch: Please check pytorch_site (https://pytorch.org/get-started/previous-versions/) to select pytorch=1.8.1 version that is compatible with your cuda version.\n",
        "You can check the cuda version of your server with 'nvidia-smi' or 'nvcc -V' to check your cuda version. Then you can run the recommended installation command (recommend pip command) from the website in this environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0df5fc6f-b94e-4497-914e-b3e717c3a959",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Install required Python packages\n",
        "pip install easydict opencv-python simplejson lvis Pillow==9.5.0 pytorch_msssim \n",
        "pip install pandas hic-straw matplotlib scikit-image scipy einops tensorboard cooler numba pyBigWig timm==0.3.2\n",
        "\n",
        "\n",
        "# Clone HiCFoundation repositories\n",
        "git clone https://github.com/Noble-Lab/HiCFoundation.git\n",
        "git clone https://github.com/Noble-Lab/HiCFoundation_paper.git"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bee132f-1da5-4b62-8434-a2070a967dd3",
      "metadata": {},
      "source": [
        "Create Directory Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3444ec3d-4217-4867-babc-109cc4bbdad3",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create necessary directories\n",
        "dirs_to_create = [\n",
        "    'utils', \n",
        "    'input-dirs', \n",
        "    'input-dirs/pre-train-dirs', \n",
        "    'ft-inputs', \n",
        "    'outputs', \n",
        "    'models'\n",
        "]\n",
        "\n",
        "for dir_name in dirs_to_create:\n",
        "    os.makedirs(dir_name, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ca2ecce-a0fc-4c15-8f33-9b50da70f656",
      "metadata": {},
      "source": [
        "Check GPU Availability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "496040bc-26f9-47cd-b15f-abc3be36eec2",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e000840f-ee9b-492b-846b-3cbf3d1f3d35",
      "metadata": {},
      "source": [
        "Download data from here: \n",
        "https://drive.google.com/drive/folders/1D5MqwauHKRFixhRbGljSnouxWFNVfL1l?usp=sharing "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c0e498b-b7b1-4162-9b52-c092d65c2b15",
      "metadata": {},
      "source": [
        "Data Preprocessing:\n",
        "1. Create hic2array.py\n",
        "Save this as utils/hic2array.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc6a7805-f4c3-4b7a-9afb-34b536b3e325",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.sparse import coo_matrix\n",
        "import hicstraw\n",
        "import os\n",
        "import pickle \n",
        "\n",
        "def write_pkl(data, path):\n",
        "    with open(path, 'wb') as f:\n",
        "        pickle.dump(data, f)\n",
        "\n",
        "def read_chrom_array(chr1, chr2, normalization, hic_file, resolution):\n",
        "    chr1_name = chr1.name\n",
        "    chr2_name = chr2.name\n",
        "    infos = []\n",
        "    infos.append('observed')\n",
        "    infos.append(normalization)\n",
        "    infos.append(hic_file)\n",
        "    infos.append(chr1_name)\n",
        "    infos.append(chr2_name)\n",
        "    infos.append('BP')\n",
        "    infos.append(resolution)\n",
        "    print(infos)\n",
        "    row, col, val = [], [], []\n",
        "    rets = hicstraw.straw(*infos)\n",
        "    print('\\tlen(rets): {:3e}'.format(len(rets)))\n",
        "    for ret in rets:\n",
        "        row.append((int)(ret.binX // resolution))\n",
        "        col.append((int)(ret.binY // resolution))\n",
        "        val.append(ret.counts)\n",
        "    print('\\tsum(val): {:3e}'.format(sum(val)))\n",
        "    if sum(val) == 0:\n",
        "        return None\n",
        "    if chr1_name==chr2_name:\n",
        "        max_shape =max(max(row),max(col))+1\n",
        "        mat_coo = coo_matrix((val, (row, col)), shape = (max_shape,max_shape),dtype=np.float32)\n",
        "    else:\n",
        "        max_row = max(row)+1\n",
        "        max_column = max(col)+1\n",
        "        mat_coo = coo_matrix((val, (row, col)), shape = (max_row,max_column),dtype=np.float32)\n",
        "\n",
        "    mat_coo = mat_coo #+ triu(mat_coo, 1).T #no below diagonaline records\n",
        "\n",
        "    return mat_coo\n",
        "\n",
        "\n",
        "def hic2array(input_hic,output_pkl=None,\n",
        "              resolution=25000,normalization=\"NONE\",\n",
        "              tondarray=0):\n",
        "    \"\"\"\n",
        "    input_hic: str, input hic file path\n",
        "    output_pkl: str, output pickle file path\n",
        "    resolution: int, resolution of the hic file\n",
        "    \"\"\"\n",
        "\n",
        "    hic = hicstraw.HiCFile(input_hic)\n",
        "    chrom_list=[]\n",
        "    chrom_dict={}\n",
        "    for chrom in hic.getChromosomes():\n",
        "        print(chrom.name, chrom.length)\n",
        "        if \"all\" in chrom.name.lower():\n",
        "            continue\n",
        "        chrom_list.append(chrom)\n",
        "        chrom_dict[chrom.name]=chrom.length\n",
        "    resolution_list = hic.getResolutions()\n",
        "    if resolution not in resolution_list:\n",
        "        print(\"Resolution not found in the hic file, please choose from the following list:\")\n",
        "        print(resolution_list)\n",
        "        exit()\n",
        "    output_dict={}\n",
        "    for i in range(len(chrom_list)):\n",
        "        for j in range(i,len(chrom_list)):\n",
        "            if i!=j and tondarray in [2,3]:\n",
        "                #skip inter-chromosome region\n",
        "                continue\n",
        "            \n",
        "            chrom1 = chrom_list[i]\n",
        "            chrom1_name = chrom_list[i].name\n",
        "            chrom2 = chrom_list[j]\n",
        "            chrom2_name = chrom_list[j].name\n",
        "            if 'Un' in chrom1_name or 'Un' in chrom2_name:\n",
        "                continue\n",
        "            if \"random\" in chrom1_name.lower() or \"random\" in chrom2_name.lower():\n",
        "                continue\n",
        "            if \"alt\" in chrom1_name.lower() or \"alt\" in chrom2_name.lower():\n",
        "                continue\n",
        "            read_array=read_chrom_array(chrom1,chrom2, normalization, input_hic, resolution)\n",
        "            if read_array is None:\n",
        "                print(\"No data found for\",chrom1_name,chrom2_name)\n",
        "                continue\n",
        "            if tondarray in [1,3]:\n",
        "                read_array = read_array.toarray()\n",
        "            if tondarray in [2,3]:\n",
        "                output_dict[chrom1_name]=read_array\n",
        "            else:\n",
        "                output_dict[chrom1_name+\"_\"+chrom2_name]=read_array\n",
        "    if output_pkl is not None:\n",
        "        output_dir = os.path.dirname(os.path.realpath(output_pkl))\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        write_pkl(output_dict,output_pkl)\n",
        "\n",
        "    return output_dict\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import os \n",
        "    import sys\n",
        "    if len(sys.argv) != 6:\n",
        "        print('Usage: python3 hic2array.py [input.hic] [output.pkl] [resolution] [normalization_type] [mode]')\n",
        "        print(\"This is the full hic2array script. \")\n",
        "        print(\"normalization type: 0: None normalization; 1: VC normalization; 2: VC_SQRT normalization; 3: KR normalization; 4: SCALE normalization\")\n",
        "        print(\"mode: 0 for sparse matrix, 1 for dense matrix, 2 for sparce matrix (only cis-contact); 3 for dense matrix (only cis-contact).\")\n",
        "        sys.exit(1)\n",
        "    resolution = int(sys.argv[3])\n",
        "    normalization_type = int(sys.argv[4])\n",
        "    mode = int(sys.argv[5])\n",
        "    normalization_dict={0:\"NONE\",1:\"VC\",2:\"VC_SQRT\",3:\"KR\",4:\"SCALE\"}\n",
        "    if normalization_type not in normalization_dict:\n",
        "        print('normalization type should be 0,1,2,3,4')\n",
        "        print(\"normalization type: 0: None normalization; 1: VC normalization; 2: VC_SQRT normalization; 3: KR normalization; 4: SCALE normalization\")\n",
        "        sys.exit(1)\n",
        "    normalization_type = normalization_dict[normalization_type]\n",
        "    if mode not in [0,1,2,3]:\n",
        "        print('mode should be in choice of 0/1/2/3')\n",
        "        print(\"mode: 0 for sparse matrix, 1 for dense matrix, 2 for sparce matrix (only cis-contact); 3 for dense matrix (only cis-contact).\")\n",
        "        sys.exit(1)\n",
        "    input_hic_path = os.path.abspath(sys.argv[1])\n",
        "    output_pkl_path = os.path.abspath(sys.argv[2])\n",
        "    output_dir = os.path.dirname(output_pkl_path)\n",
        "    os.makedirs(output_dir,exist_ok=True)\n",
        "    hic2array(input_hic_path,output_pkl_path,resolution,normalization_type,mode)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec10ccc5-a779-43e9-b8e1-164bfac3f6bb",
      "metadata": {},
      "source": [
        "Submatrix Generation:\n",
        "1. Create scan_array.py\n",
        "Save this as utils/scan_array.py:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25a03070-efbf-404f-b571-ef3426a72d1c",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from scipy.sparse import coo_matrix\n",
        "import os\n",
        "\n",
        "def write_pickle(output_dict,output_path):\n",
        "    \"\"\"\n",
        "    output_dict: dict, output dictionary\n",
        "    output_path: str, output path\n",
        "    \"\"\"\n",
        "    with open(output_path, 'wb') as f:\n",
        "        pickle.dump(output_dict, f)\n",
        "\n",
        "def scan_matrix(matrix, input_row_size,input_col_size, stride_row,\n",
        "                stride_col,hic_count,output_dir,current_chrom,\n",
        "                filter_threshold=0.05):\n",
        "    \"\"\"\n",
        "    matrix: 2D array\n",
        "    input_row_size: int, row size of scanned output submatrix\n",
        "    input_col_size: int, column size of scanned output submatrix\n",
        "    stride_row: int, row stride\n",
        "    stride_col: int, column stride\n",
        "    hic_count: int, total read count of the Hi-C experiments\n",
        "    output_dir: str, output directory\n",
        "    current_chrom: str, current chromosome\n",
        "    \"\"\"\n",
        "    row_size = matrix.shape[0]\n",
        "    col_size = matrix.shape[1]\n",
        "    count_save=0\n",
        "    region_size = input_row_size * input_col_size\n",
        "    for i in range(0, row_size - input_row_size//2, stride_row):\n",
        "        for j in range(0, col_size - input_col_size//2, stride_col):\n",
        "            submatrix = np.zeros((input_row_size, input_col_size))\n",
        "            row_start = max(0,i)\n",
        "            row_end = min(row_size, i + input_row_size)\n",
        "            col_start = max(0,j)\n",
        "            col_end = min(col_size, j + input_col_size)\n",
        "            submatrix[:row_end-row_start,:col_end-col_start] = matrix[row_start: row_end, col_start: col_end]\n",
        "            #filter out the submatrices with too many zeros\n",
        "            count_useful = np.count_nonzero(submatrix)\n",
        "            if count_useful < region_size * filter_threshold:\n",
        "                continue\n",
        "            \n",
        "            output_dict={}\n",
        "            output_dict['input']=submatrix\n",
        "            output_dict['input_count']=hic_count\n",
        "            #judge if the diag is possibly included\n",
        "            if col_start < row_start and col_end >row_start:\n",
        "                output_dict['diag']=abs (col_start-row_start)\n",
        "            elif col_start == row_start:\n",
        "                output_dict['diag']=0\n",
        "            elif col_start> row_start and col_start < row_end:\n",
        "                output_dict['diag']= -abs (col_start-row_start)\n",
        "            else:\n",
        "                output_dict['diag']=None\n",
        "            output_path = os.path.join(output_dir, str(current_chrom) + '_' + str(i) + '_' + str(j) + '.pkl')\n",
        "            write_pickle(output_dict,output_path)\n",
        "            count_save+=1\n",
        "            if count_save%100==0:\n",
        "                print('Processed %d submatrices' % count_save, \" for chromosome \", current_chrom)\n",
        "        \n",
        "    return \n",
        "\n",
        "def scan_pickle(input_pkl_path, input_row_size,input_col_size, stride_row,\n",
        "                stride_col,output_dir,filter_threshold):\n",
        "    \"\"\"\n",
        "    input_pkl_path: str, input pickle path  \n",
        "    input_row_size: int, row size of scanned output submatrix\n",
        "    input_col_size: int, column size of scanned output submatrix\n",
        "    stride_row: int, row stride\n",
        "    stride_col: int, column stride\n",
        "    output_dir: str, output directory\n",
        "    \"\"\"\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    with open(input_pkl_path, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    total_count = 0\n",
        "    for key in data:\n",
        "        matrix = data[key]\n",
        "        if isinstance(matrix, np.ndarray):\n",
        "            cur_count = np.sum(matrix)\n",
        "        elif isinstance(matrix, coo_matrix):\n",
        "            cur_count = matrix.sum()\n",
        "        else:\n",
        "            print(\"Type not supported\", type(matrix))\n",
        "            exit()\n",
        "        total_count += cur_count\n",
        "    print(\"Total read count of Hi-C: \", total_count)        \n",
        "\n",
        "    for key in data:\n",
        "        matrix = data[key]\n",
        "        if isinstance(matrix, coo_matrix):\n",
        "            matrix = matrix.toarray()\n",
        "            \n",
        "            if matrix.shape[0]==matrix.shape[1]:\n",
        "                #intra chromosmoe\n",
        "                #get the symmetrical one \n",
        "                upper_tri = np.triu(matrix,1)\n",
        "                all_triu = np.triu(matrix)\n",
        "                matrix = all_triu + upper_tri.T\n",
        "            else:\n",
        "                matrix = matrix\n",
        "        current_chrom = str(key)\n",
        "        if \"chr\" not in current_chrom:\n",
        "            current_chrom = \"chr\" + current_chrom\n",
        "\n",
        "        scan_matrix(matrix, input_row_size,input_col_size, stride_row,\n",
        "                stride_col,total_count,output_dir,current_chrom,filter_threshold)\n",
        "\n",
        "#run with the simple command line\n",
        "if __name__ == '__main__':\n",
        "    import argparse\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--input_pkl_path', type=str, required=True)\n",
        "    parser.add_argument('--input_row_size', type=int, required=True)\n",
        "    parser.add_argument('--input_col_size', type=int, required=True)\n",
        "    parser.add_argument('--stride_row', type=int, required=True)\n",
        "    parser.add_argument('--stride_col', type=int, required=True)\n",
        "    parser.add_argument('--output_dir', type=str, required=True)\n",
        "    parser.add_argument('--filter_threshold', type=float, default=0.05)\n",
        "    args = parser.parse_args()\n",
        "    input_pkl_path = os.path.abspath(args.input_pkl_path)\n",
        "    output_dir = os.path.abspath(args.output_dir)\n",
        "    scan_pickle(input_pkl_path, args.input_row_size, args.input_col_size, \n",
        "                args.stride_row, args.stride_col, output_dir, args.filter_threshold)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c41807a0-c975-4612-a5e6-4b999afeb3b1",
      "metadata": {},
      "source": [
        "2. Create .pkl files from .hci files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "723226ef-dfbc-4712-9086-283169766aa7",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "python3 hic2array.py Ft1-GSM6077013_at_hic_ndx1-4_r2.hic Ftr1.pkl 25000 0 0 \n",
        "&& python3 hic2array.py Pt1-GSM4705443_ddcc.hic Ptr1.pkl 25000 0 0 \n",
        "&& python3 hic2array.py Pt2-GSM6077012_at_hic_ndx1-4_r1.hic Ptr2.pkl 25000 0 0 \n",
        "&& python3 hic2array.py Pv1-GSM5091844_S_WT_2h1_DNB-15.allValidPairs.hic Pv1.pkl 25000 0 0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20229a36-f909-4386-803c-16aed36f02cc",
      "metadata": {},
      "source": [
        "3. Generate Submatrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f805f30-d548-40f5-bad4-2716aa7a9278",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Generate submatrices for pre-training\n",
        "python3 utils/scan_array.py --input_pkl_path Ptr1.pkl  --input_row_size 448 \\\n",
        "    --input_col_size 448 --stride_row 224 --stride_col 224 \\\n",
        "    --output_dir HiC-PTR1 --filter_threshold 0.01\n",
        "\n",
        "python3 utils/scan_array.py --input_pkl_path Ptr2.pkl  --input_row_size 448 \\\n",
        "    --input_col_size 448 --stride_row 224 --stride_col 224 \\\n",
        "    --output_dir HiC-PTR2 --filter_threshold 0.01\n",
        "\n",
        "python3 utils/scan_array.py --input_pkl_path Pv1.pkl  --input_row_size 448 \\\n",
        "    --input_col_size 448 --stride_row 224 --stride_col 224 \\\n",
        "    --output_dir HiC-PV1 --filter_threshold 0.01"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e46a4573-360d-4871-bd82-0d08bd11a035",
      "metadata": {},
      "source": [
        "4. Create Configuration Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "656b792e-73e4-4d45-b2d8-e4d5a8c1d3bb",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Create train.txt\n",
        "echo \"HiC-PTR1\" > input-dirs/pre-train-dirs/train.txt\n",
        "echo \"HiC-PTR2\" >> input-dirs/pre-train-dirs/train.txt\n",
        "\n",
        "# Create val.txt\n",
        "echo \"HiC-PV1\" > input-dirs/pre-train-dirs/val.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09b6fb4d-102d-4613-99da-3a3a27467f4b",
      "metadata": {},
      "source": [
        "Pre-training:\n",
        "Run the pre-training command"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c8bcb97-b1b1-4917-9170-48b4d6986be2",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "python3 pretrain.py --batch_size 1 --accum_iter 4 \\\n",
        "    --epochs 1 --warmup_epochs 1 --pin_mem \\\n",
        "    --mask_ratio 0.75 --sparsity_ratio 0.05 \\\n",
        "    --blr 1.5e-4 --min_lr 1e-7 --weight_decay 0.05 \\\n",
        "    --model \"vit_large_patch16\" --loss_alpha 1 --seed 888 \\\n",
        "    --data_path \"input-dirs/pre-train-dirs/\" --train_config \"train.txt\" \\\n",
        "    --valid_config \"val.txt\" --output \"hicfoundation_finetune\" \\\n",
        "    --tensorboard 1 --world_size 1 --dist_url \"tcp://localhost:10001\" --rank 0 \\\n",
        "    --input_row_size 448 --input_col_size 448 --patch_size 16 \\\n",
        "    --print_freq 1 --save_freq 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ded2894-b015-4fca-a7f9-de71687f90a3",
      "metadata": {},
      "source": [
        "After training, rename the output directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b58a77d3-321c-4f33-9636-8b235fdd093f",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "mv hicfoundation_finetune hicfoundation_pretrain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcc239ff-fef3-47d9-9ade-88f4bf9c17e0",
      "metadata": {},
      "source": [
        "Fine-tuning Preparation\n",
        "1. Create downsample_pkl.py\n",
        "Save this as utils/downsample_pkl.py:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61642212-3105-4f5d-991e-1f9ba8615588",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import pickle\n",
        "import numpy as np\n",
        "from scipy.sparse import coo_matrix\n",
        "\n",
        "def array_to_coo(array):\n",
        "    \"\"\"\n",
        "    Convert a regular 2D NumPy array to a scipy.sparse.coo_matrix.\n",
        "\n",
        "    Parameters:\n",
        "    - array (numpy.ndarray): The input 2D array.\n",
        "\n",
        "    Returns:\n",
        "    - scipy.sparse.coo_matrix: The converted COO matrix.\n",
        "    \"\"\"\n",
        "    # Find the non-zero elements in the array\n",
        "    row, col = np.nonzero(array)\n",
        "\n",
        "    # Get the values of the non-zero elements\n",
        "    data = array[row, col]\n",
        "\n",
        "    # Create the COO matrix\n",
        "    coo_mat = coo_matrix((data, (row, col)), shape=array.shape)\n",
        "\n",
        "    return coo_mat\n",
        "\n",
        "def sparse2tag(coo_mat):\n",
        "    tag_len = coo_mat.sum()\n",
        "    tag_len = int(tag_len)\n",
        "    tag_mat = np.zeros((tag_len, 2))\n",
        "    tag_mat = tag_mat.astype(int)\n",
        "    row, col, data = coo_mat.row, coo_mat.col, coo_mat.data\n",
        "    start_idx = 0\n",
        "    for i in range(len(row)):\n",
        "        end_idx = start_idx + int(data[i])\n",
        "        tag_mat[start_idx:end_idx, :] = (row[i], col[i])\n",
        "        start_idx = end_idx\n",
        "    return tag_mat, tag_len\n",
        "\n",
        "def tag2sparse(tag, nsize):\n",
        "    \"\"\"\n",
        "    Coverts a coo-based tag matrix to sparse matrix.\n",
        "    \"\"\"\n",
        "    coo_data, data = np.unique(tag, axis=0, return_counts=True)\n",
        "    row, col = coo_data[:, 0], coo_data[:, 1]\n",
        "    sparse_mat = coo_matrix((data, (row, col)), shape=(nsize, nsize))\n",
        "    return sparse_mat\n",
        "\n",
        "def downsampling_sparce(matrix, down_ratio, verbose=False):\n",
        "    \"\"\"\n",
        "    Downsampling method for sparse matrix.\n",
        "    \"\"\"\n",
        "    if verbose: print(f\"[Downsampling] Matrix shape is {matrix.shape}\")\n",
        "    tag_mat, tag_len = sparse2tag(matrix)\n",
        "    sample_idx = np.random.choice(tag_len, int(tag_len *down_ratio))\n",
        "    sample_tag = tag_mat[sample_idx]\n",
        "    if verbose: print(f'[Downsampling] Sampling {down_ratio} of {tag_len} reads')\n",
        "    down_mat = tag2sparse(sample_tag, matrix.shape[0])\n",
        "    return down_mat\n",
        "\n",
        "\n",
        "def downsample_pkl(input_pkl, output_pkl, downsample_rate):\n",
        "    data = pickle.load(open(input_pkl, 'rb'))\n",
        "    return_dict={}\n",
        "    for chrom in data:\n",
        "        current_data = data[chrom]\n",
        "        if current_data.shape[0] <=100:\n",
        "            continue\n",
        "        #if it is numpy array convert to sparse matrix\n",
        "        if isinstance(current_data, np.ndarray):\n",
        "            current_data = array_to_coo(current_data)\n",
        "            \n",
        "        downsampled_data = downsampling_sparce(current_data, downsample_rate,verbose=1)\n",
        "        return_dict[chrom] = downsampled_data\n",
        "    pickle.dump(return_dict, open(output_pkl, \"wb\"))\n",
        "    print(\"finish downsampling %s\"%output_pkl)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if len(sys.argv)!=4:\n",
        "        print(\"Usage: python3 downsample_pkl.py [input.pkl] [output.pkl] [downsample_rate]\")\n",
        "        print(\"This script is used to downsample the input pickle file.\")\n",
        "        print(\"[input.pkl]: the input pickle file\")\n",
        "        print(\"[output.pkl]: the output pickle file\")\n",
        "        print(\"[downsample_rate]: the downsample rate [float].\")\n",
        "        sys.exit(1)\n",
        "    input_pkl = os.path.abspath(sys.argv[1])\n",
        "    output_pkl = os.path.abspath(sys.argv[2])\n",
        "    output_dir = os.path.dirname(output_pkl)\n",
        "    os.makedirs(output_dir, exist_ok=True)    \n",
        "    downsample_rate = float(sys.argv[3])\n",
        "    downsample_pkl(input_pkl, output_pkl, downsample_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2908137b-f102-4c68-9bdc-1318b8c0f2e1",
      "metadata": {},
      "source": [
        "2. Downsample Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79aff2b6-506e-4841-9f8d-cda523dfd5aa",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "python3 utils/downsample_pkl.py Ftr1.pkl Ftr1_downsampled.pkl 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c29eff0-a8e7-434c-98d0-2b55ac31511a",
      "metadata": {},
      "source": [
        "3. Create scan_array_diag.py\n",
        "Save this as utils/scan_array_diag.py:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dae5a319-491f-4241-b90a-e33e2e430342",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from scipy.sparse import coo_matrix\n",
        "import os\n",
        "\n",
        "def write_pickle(output_dict,output_path):\n",
        "    \"\"\"\n",
        "    output_dict: dict, output dictionary\n",
        "    output_path: str, output path\n",
        "    \"\"\"\n",
        "    with open(output_path, 'wb') as f:\n",
        "        pickle.dump(output_dict, f)\n",
        "\n",
        "def scan_matrix_paired(original_matrix, downsampled_matrix, input_row_size, input_col_size, stride,\n",
        "                      hic_count, output_dir, current_chrom):\n",
        "    \"\"\"\n",
        "    original_matrix: 2D array, original high-quality Hi-C matrix\n",
        "    downsampled_matrix: 2D array, downsampled low-quality Hi-C matrix\n",
        "    input_row_size: int, row size of scanned output submatrix\n",
        "    input_col_size: int, column size of scanned output submatrix\n",
        "    stride: int, row stride\n",
        "    hic_count: int, total read count of the Hi-C experiments\n",
        "    output_dir: str, output directory\n",
        "    current_chrom: str, current chromosome\n",
        "    \"\"\"\n",
        "    row_size = original_matrix.shape[0]\n",
        "    col_size = original_matrix.shape[1]\n",
        "    count_save = 0\n",
        "    \n",
        "    # Ensure both matrices have the same dimensions\n",
        "    assert original_matrix.shape == downsampled_matrix.shape, \\\n",
        "        f\"Matrix shapes don't match: {original_matrix.shape} vs {downsampled_matrix.shape}\"\n",
        "    \n",
        "    print(f\"Scanning matrix {current_chrom} with shape {original_matrix.shape}\")\n",
        "    print(f\"Submatrix size: {input_row_size}x{input_col_size}, stride: {stride}\")\n",
        "    \n",
        "    # For rectangular matrices, scan with different patterns\n",
        "    if row_size == col_size:\n",
        "        # Square matrix: use diagonal scanning\n",
        "        for i in range(0, row_size - input_row_size + 1, stride):\n",
        "            j = i  # Diagonal scanning\n",
        "            if j + input_col_size > col_size:\n",
        "                continue\n",
        "                \n",
        "            original_submatrix = original_matrix[i:i+input_row_size, j:j+input_col_size]\n",
        "            downsampled_submatrix = downsampled_matrix[i:i+input_row_size, j:j+input_col_size]\n",
        "            \n",
        "            # Filter out submatrices with too many zeros\n",
        "            count_useful = np.count_nonzero(original_submatrix)\n",
        "            if count_useful < 1:\n",
        "                continue\n",
        "            \n",
        "            # Create paired output dictionary\n",
        "            output_dict = {}\n",
        "            output_dict['input'] = downsampled_submatrix.copy()\n",
        "            output_dict['2d_target'] = original_submatrix.copy()\n",
        "            output_dict['input_count'] = hic_count\n",
        "            \n",
        "            output_path = os.path.join(output_dir, str(current_chrom) + '_' + str(i) + '_' + str(j) + '.pkl')\n",
        "            write_pickle(output_dict, output_path)\n",
        "            count_save += 1\n",
        "            \n",
        "            if count_save % 100 == 0:\n",
        "                print('Processed %d paired submatrices' % count_save, \" for chromosome \", current_chrom)\n",
        "    else:\n",
        "        # Rectangular matrix: scan all possible positions\n",
        "        for i in range(0, row_size - input_row_size + 1, stride):\n",
        "            for j in range(0, col_size - input_col_size + 1, stride):\n",
        "                original_submatrix = original_matrix[i:i+input_row_size, j:j+input_col_size]\n",
        "                downsampled_submatrix = downsampled_matrix[i:i+input_row_size, j:j+input_col_size]\n",
        "                \n",
        "                # Filter out submatrices with too many zeros\n",
        "                count_useful = np.count_nonzero(original_submatrix)\n",
        "                if count_useful < 1:\n",
        "                    continue\n",
        "                \n",
        "                # Create paired output dictionary\n",
        "                output_dict = {}\n",
        "                output_dict['input'] = downsampled_submatrix.copy()\n",
        "                output_dict['2d_target'] = original_submatrix.copy()\n",
        "                output_dict['input_count'] = hic_count\n",
        "                \n",
        "                output_path = os.path.join(output_dir, str(current_chrom) + '_' + str(i) + '_' + str(j) + '.pkl')\n",
        "                write_pickle(output_dict, output_path)\n",
        "                count_save += 1\n",
        "                \n",
        "                if count_save % 100 == 0:\n",
        "                    print('Processed %d paired submatrices' % count_save, \" for chromosome \", current_chrom)\n",
        "    \n",
        "    print(f\"Total submatrices saved for {current_chrom}: {count_save}\")\n",
        "    return \n",
        "\n",
        "def scan_pickle_paired(original_pkl_path, downsampled_pkl_path, input_row_size, input_col_size, \n",
        "                      stride, output_dir):\n",
        "    \"\"\"\n",
        "    original_pkl_path: str, path to original (high-quality) pickle file\n",
        "    downsampled_pkl_path: str, path to downsampled (low-quality) pickle file  \n",
        "    input_row_size: int, row size of scanned output submatrix\n",
        "    input_col_size: int, column size of scanned output submatrix\n",
        "    stride: int, row stride\n",
        "    output_dir: str, output directory\n",
        "    \"\"\"\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Load both pickle files\n",
        "    with open(original_pkl_path, 'rb') as f:\n",
        "        original_data = pickle.load(f)\n",
        "    \n",
        "    with open(downsampled_pkl_path, 'rb') as f:\n",
        "        downsampled_data = pickle.load(f)\n",
        "    \n",
        "    # Ensure both datasets have the same chromosomes\n",
        "    assert set(original_data.keys()) == set(downsampled_data.keys()), \\\n",
        "        \"Original and downsampled data must have the same chromosomes\"\n",
        "    \n",
        "    # Calculate total count from original data\n",
        "    total_count = 0\n",
        "    for key in original_data:\n",
        "        matrix = original_data[key]\n",
        "        if isinstance(matrix, np.ndarray):\n",
        "            cur_count = np.sum(matrix)\n",
        "        elif isinstance(matrix, coo_matrix):\n",
        "            cur_count = matrix.sum()\n",
        "        else:\n",
        "            print(\"Type not supported\", type(matrix))\n",
        "            exit()\n",
        "        total_count += cur_count\n",
        "    print(\"Total read count of original Hi-C: \", total_count)        \n",
        "\n",
        "    # Process each chromosome\n",
        "    for key in original_data:\n",
        "        original_matrix = original_data[key]\n",
        "        downsampled_matrix = downsampled_data[key]\n",
        "        \n",
        "        # Convert sparse matrices to dense arrays\n",
        "        if isinstance(original_matrix, coo_matrix):\n",
        "            original_matrix = original_matrix.toarray()\n",
        "        \n",
        "        if isinstance(downsampled_matrix, coo_matrix):\n",
        "            downsampled_matrix = downsampled_matrix.toarray()\n",
        "        \n",
        "        current_chrom = str(key)\n",
        "        if \"chr\" not in current_chrom:\n",
        "            current_chrom = \"chr\" + current_chrom\n",
        "        \n",
        "        # Only apply symmetry operation if matrix is square\n",
        "        if original_matrix.shape[0] == original_matrix.shape[1]:\n",
        "            # Get the symmetrical matrix for square matrices\n",
        "            upper_tri = np.triu(original_matrix, 1)\n",
        "            all_triu = np.triu(original_matrix)\n",
        "            original_matrix = all_triu + upper_tri.T\n",
        "            \n",
        "            upper_tri = np.triu(downsampled_matrix, 1)\n",
        "            all_triu = np.triu(downsampled_matrix)\n",
        "            downsampled_matrix = all_triu + upper_tri.T\n",
        "        else:\n",
        "            print(f\"Warning: Matrix for {current_chrom} is not square ({original_matrix.shape}). Skipping symmetry operation.\")\n",
        "\n",
        "        print(f\"Processing chromosome {current_chrom}\")\n",
        "        print(f\"Original matrix shape: {original_matrix.shape}\")\n",
        "        print(f\"Downsampled matrix shape: {downsampled_matrix.shape}\")\n",
        "\n",
        "        scan_matrix_paired(original_matrix, downsampled_matrix, input_row_size, input_col_size, \n",
        "                          stride, total_count, output_dir, current_chrom)\n",
        "\n",
        "# Run with the simple command line\n",
        "if __name__ == '__main__':\n",
        "    import argparse\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--original_pkl_path', type=str, required=True, \n",
        "                      help='Path to original (high-quality) pickle file')\n",
        "   parser.add_argument('--downsampled_pkl_path', type=str, required=True,\n",
        "                      help='Path to downsampled (low-quality) pickle file')\n",
        "   parser.add_argument('--input_row_size', type=int, required=True)\n",
        "   parser.add_argument('--input_col_size', type=int, required=True)\n",
        "   parser.add_argument('--stride', type=int, required=True)\n",
        "   parser.add_argument('--output_dir', type=str, required=True)\n",
        "   args = parser.parse_args()\n",
        "   \n",
        "   original_pkl_path = os.path.abspath(args.original_pkl_path)\n",
        "   downsampled_pkl_path = os.path.abspath(args.downsampled_pkl_path)\n",
        "   output_dir = os.path.abspath(args.output_dir)\n",
        "   \n",
        "   scan_pickle_paired(original_pkl_path, downsampled_pkl_path, args.input_row_size, \n",
        "                     args.input_col_size, args.stride, output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73399045-c5a7-4e31-9a22-127d7b1a1f45",
      "metadata": {},
      "source": [
        "4. Generate Paired Submatrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5f00a20-e90b-4a19-9e9d-8abf54be9043",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "python3 utils/scan_array_diag.py \\\n",
        "    --original_pkl_path Ftr1.pkl \\\n",
        "    --downsampled_pkl_path Ftr1_downsampled.pkl \\\n",
        "    --input_row_size 224 --input_col_size 224 --stride 20 \\\n",
        "    --output_dir Ftr1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66109171-8223-4726-875f-2bc8e1fddefa",
      "metadata": {},
      "source": [
        "5. Prepare Fine-tuning Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15eeac19-6034-4676-96a4-e182589c3f7c",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Get all pkl files from Ftr1 directory\n",
        "ftr1_files = glob.glob('Ftr1/*.pkl')\n",
        "\n",
        "# Shuffle and split (80-20 split)\n",
        "random.shuffle(ftr1_files)\n",
        "split_idx = int(0.8 * len(ftr1_files))\n",
        "\n",
        "train_files = ftr1_files[:split_idx]\n",
        "val_files = ftr1_files[split_idx:]\n",
        "\n",
        "# Create directories for fine-tuning\n",
        "os.makedirs('ft-inputs/train', exist_ok=True)\n",
        "os.makedirs('ft-inputs/val', exist_ok=True)\n",
        "\n",
        "# Copy files to respective directories\n",
        "for f in train_files:\n",
        "    shutil.copy(f, 'ft-inputs/train/')\n",
        "for f in val_files:\n",
        "    shutil.copy(f, 'ft-inputs/val/')\n",
        "\n",
        "# Create configuration files\n",
        "with open('ft-inputs/train_config.txt', 'w') as f:\n",
        "    f.write('train\\n')\n",
        "\n",
        "with open('ft-inputs/val_config.txt', 'w') as f:\n",
        "    f.write('val\\n')\n",
        "\n",
        "print(f\"Created fine-tuning dataset: {len(train_files)} train, {len(val_files)} validation samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "009bf5ee-b465-4e4e-a1d9-7ac073183616",
      "metadata": {},
      "source": [
        "Fine-tuning:\n",
        "1. Modified train_epoch.py\n",
        "Save this modified version as finetune/train_epoch.py:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a2b1b61-7d3f-4b4a-a612-f99a2fd62363",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import sys\n",
        "import numpy as np\n",
        "from typing import Iterable\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "from ops.Logger import MetricLogger,SmoothedValue\n",
        "import model.lr_sched as lr_sched\n",
        "from finetune.loss import configure_loss\n",
        "from ops.train_utils import list_to_device, to_value, create_image, torch_to_nparray, convert_gray_rgbimage\n",
        "\n",
        "\n",
        "def train_epoch(model, data_loader_train, optimizer, \n",
        "                loss_scaler, epoch, device,\n",
        "                log_writer=None, args=None):\n",
        "    model.train()\n",
        "    metric_logger = MetricLogger(delimiter=\"  \")\n",
        "    metric_logger.add_meter('lr', SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
        "\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "    print_freq = args.print_freq\n",
        "\n",
        "    accum_iter = args.accum_iter\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    if log_writer is not None:\n",
        "        print('Tensorboard log dir: {}'.format(log_writer.log_dir))\n",
        "    print(\"number of iterations: \",len(data_loader_train))\n",
        "    criterion = configure_loss(args)\n",
        "\n",
        "    num_iter = len(data_loader_train)\n",
        "    for data_iter_step, train_data in enumerate(metric_logger.log_every(data_loader_train, print_freq, header)):\n",
        "        if data_iter_step % accum_iter == 0:\n",
        "            lr_sched.adjust_learning_rate(optimizer, data_iter_step / len(data_loader_train) + epoch, args)\n",
        "        input_matrix, total_count, target_matrix, embed_target, target_vector = list_to_device(train_data,device=device)\n",
        "        \n",
        "        # Forward pass\n",
        "        output_embedding, output_2d, output_1d = model(input_matrix, total_count)\n",
        "        \n",
        "        # Calculate losses - ensure all outputs participate in loss calculation\n",
        "        loss_components = []\n",
        "        \n",
        "        if embed_target is not None:\n",
        "            embedding_loss = criterion(output_embedding, embed_target)\n",
        "            loss_components.append(embedding_loss)\n",
        "        else:\n",
        "            # Use a small multiplier on the output to ensure gradients flow\n",
        "            # but don't affect the actual loss value\n",
        "            embedding_loss = 0.0 * output_embedding.mean()\n",
        "            loss_components.append(embedding_loss)\n",
        "            \n",
        "        if target_matrix is not None:\n",
        "            #flatten 2d matrix\n",
        "            output_2d_flatten = torch.flatten(output_2d, start_dim=1,end_dim=-1)\n",
        "            target_matrix_flatten = torch.flatten(target_matrix, start_dim=1,end_dim=-1)\n",
        "            output_2d_loss = criterion(output_2d_flatten, target_matrix_flatten)\n",
        "            loss_components.append(output_2d_loss)\n",
        "        else:\n",
        "            # Use a small multiplier on the output to ensure gradients flow\n",
        "            output_2d_loss = 0.0 * output_2d.mean()\n",
        "            loss_components.append(output_2d_loss)\n",
        "            \n",
        "        if target_vector is not None:\n",
        "            output_1d_loss = criterion(output_1d, target_vector)\n",
        "            loss_components.append(output_1d_loss)\n",
        "        else:\n",
        "            # Use a small multiplier on the output to ensure gradients flow\n",
        "            output_1d_loss = 0.0 * output_1d.mean()\n",
        "            loss_components.append(output_1d_loss)\n",
        "        \n",
        "        # Sum all loss components\n",
        "        loss = sum(loss_components)\n",
        "        \n",
        "        # Update metrics\n",
        "        metric_logger.update(loss=to_value(loss))\n",
        "        metric_logger.update(embedding_loss=to_value(embedding_loss))\n",
        "        metric_logger.update(output_2d_loss=to_value(output_2d_loss))\n",
        "        metric_logger.update(output_1d_loss=to_value(output_1d_loss))\n",
        "        \n",
        "        if not math.isfinite(to_value(loss)):\n",
        "            print(\"Loss is {}, stopping training\".format(to_value(loss)))\n",
        "            #sys.exit(1)\n",
        "            optimizer.zero_grad()\n",
        "            continue\n",
        "            \n",
        "        loss = loss / accum_iter\n",
        "        loss_scaler(loss, optimizer, parameters=model.parameters(),\n",
        "                    update_grad=(data_iter_step + 1) % accum_iter == 0)\n",
        "\n",
        "        if (data_iter_step + 1) % accum_iter == 0:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        torch.cuda.synchronize() # Make sure all gradients are finished computing before moving on\n",
        "        lr = optimizer.param_groups[0][\"lr\"]\n",
        "        metric_logger.update(lr=lr)\n",
        "        \n",
        "\n",
        "        if log_writer is not None and ((data_iter_step + 1) % accum_iter == 0 or data_iter_step==0):\n",
        "            \"\"\" \n",
        "            We use epoch_1000x as the x-axis in tensorboard.\n",
        "            This calibrates different curves when batch size changes.\n",
        "            \"\"\"\n",
        "            epoch_1000x = int((data_iter_step / len(data_loader_train) + epoch) * 1000)\n",
        "            log_writer.add_scalars('Loss/loss', {'train_loss': to_value(loss)}, epoch_1000x)\n",
        "            log_writer.add_scalars('Loss/embedding_loss', {'train_loss': to_value(embedding_loss)}, epoch_1000x)\n",
        "            log_writer.add_scalars('Loss/output_2d_loss', {'train_loss': to_value(output_2d_loss)}, epoch_1000x)\n",
        "            log_writer.add_scalars('Loss/output_1d_loss', {'train_loss': to_value(output_1d_loss)}, epoch_1000x)\n",
        "            log_writer.add_scalars('LR/lr', {'lr': lr}, epoch_1000x)\n",
        "            if ((data_iter_step+1)//accum_iter)%50==0 or data_iter_step==0:\n",
        "                #add visualization for your output and input\n",
        "                new_samples = create_image(input_matrix)\n",
        "                select_num = min(8,len(new_samples))\n",
        "                sample_image = torch_to_nparray(new_samples.clone().detach()[:select_num])\n",
        "                log_writer.add_images('Input_%s'%\"train\", sample_image, epoch_1000x)\n",
        "                output_2d_image = convert_gray_rgbimage(output_2d.clone().detach()[:select_num])\n",
        "                output_2d_image = torch_to_nparray(output_2d_image)\n",
        "                log_writer.add_images('Output_2d_%s'%\"train\", output_2d_image, epoch_1000x)\n",
        "                # for name, param in model.named_parameters():\n",
        "                #     log_writer.add_histogram(name, param, epoch_1000x)\n",
        "                #raise errors, see https://github.com/pytorch/pytorch/issues/91516\n",
        "                #If you want to use this, install tensorboardX \n",
        "                #then change the code in main_worker.py to \"from tensorboardX import SummaryWriter\"\n",
        "    # gather the stats from all processes\n",
        "    metric_logger.synchronize_between_processes()\n",
        "    print(\"Averaged stats:\", metric_logger)\n",
        "    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fc92048-4f01-4a36-9d3d-1b319fb217a3",
      "metadata": {},
      "source": [
        "2. Run Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d67393de-aabb-4936-85f4-98e18246b8c5",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "python3 finetune.py --batch_size 1 --accum_iter 4 \\\n",
        "    --epochs 1 --warmup_epochs 0 --pin_mem \\\n",
        "    --blr 1e-3 --min_lr 1e-7 --weight_decay 0.05 \\\n",
        "    --layer_decay 0.75 --model vit_large_patch16 \\\n",
        "    --pretrain hicfoundation_pretrain/model/model_best.pth.tar \\\n",
        "    --finetune 1 --seed 888 \\\n",
        "    --loss_type 1 --data_path \"ft-inputs\" \\\n",
        "    --train_config \"train_config.txt\" \\\n",
        "    --valid_config \"val_config.txt\" \\\n",
        "    --output \"hicfoundation_finetune\" --tensorboard 1 \\\n",
        "    --world_size 1 --dist_url \"tcp://localhost:10001\" --rank 0 \\\n",
        "    --input_row_size 448 --input_col_size 448 --patch_size 16 \\\n",
        "    --print_freq 1 --save_freq 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1804da3-e672-4c9f-8138-dcb7fee42db8",
      "metadata": {},
      "source": [
        "Inference:\n",
        "First check to see if you have inference.py, main_worker.py, load_model.py and inference_worker.py from https://github.com/Noble-Lab/HiCFoundation/tree/main/inference. If you have all four of the python models installed continue from step 4. \n",
        "1. Create a directory named inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1653068b-eb07-4e3f-88b9-d8dd9866f82c",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "mkdir inference"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ec1ce70-7c84-4660-895f-e12ac7e60974",
      "metadata": {},
      "source": [
        "2. Save this as inference/inference.py:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b273164-9753-4802-8d82-9af643e04bf2",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import timm\n",
        "assert timm.__version__ == \"0.3.2\" # version check for timm\n",
        "from ops.argparser import  argparser_infer\n",
        "from ops.file_format_convert import convert_to_pkl\n",
        "\n",
        "def main(args):\n",
        "    import socket\n",
        "    hostname = socket.gethostname()\n",
        "    local_ip = socket.gethostbyname(hostname)\n",
        "    print(\"local ip: \",local_ip)\n",
        "    #format processing, convert different formats to .pkl format for further processing\n",
        "    output_dir = os.path.abspath(args.output)\n",
        "    os.makedirs(output_dir,exist_ok=True)\n",
        "    input_file = os.path.abspath(args.input)\n",
        "    config_resolution = args.resolution\n",
        "    input_pkl=convert_to_pkl(input_file, output_dir,config_resolution)\n",
        "    \n",
        "    #for reproducibility analysis, we need to smooth the matrix to generate embeddings.\n",
        "    if args.task==1:\n",
        "        from ops.smooth_matrix import smooth_pkl\n",
        "        smooth_pkl_file = os.path.join(output_dir,\"input_smoothed.pkl\")\n",
        "        input_pkl = smooth_pkl(input_pkl,smooth_pkl_file)\n",
        "        print(\"Reproducibility analysis smoothed input matrix saved to \",input_pkl)\n",
        "    from inference.main_worker import main_worker\n",
        "    main_worker(args, input_pkl)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"HiCFoundation inference started!\")\n",
        "    parser = argparser_infer()\n",
        "    args = parser.parse_args()\n",
        "    if args.gpu is not None:\n",
        "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu\n",
        "    #print mode based on --task\n",
        "    if args.task==1:\n",
        "        print(\"Reproducibility analysis\")\n",
        "    elif args.task==2:\n",
        "        print(\"Loop calling\")\n",
        "    elif args.task==3:\n",
        "        print(\"Resolution enhancement\")\n",
        "    elif args.task==4:\n",
        "        print(\"Epigenomic assay prediction\")\n",
        "    elif args.task==5:\n",
        "        print(\"scHi-C enhancement\")\n",
        "    elif args.task==6:\n",
        "        print(\"Hi-C embedding generation\")\n",
        "        embed_depth = args.embed_depth\n",
        "        if embed_depth>8:\n",
        "            print(\"Error: embed_depth is larger than 8, that is beyond decoder depth. Please set embed_depth<=8\")\n",
        "            print(\"0 indicates the encoder output, k indicates the k-th decoder layer's output\")\n",
        "            exit(1)\n",
        "    else:\n",
        "        print(\"Unknown task specified \",args.task)\n",
        "        print(\"Please specify the task using --task with 1,2,3,4,5,6\")\n",
        "        exit(1)\n",
        "    #check the specied input size, must be a multiple of args.patch_size\n",
        "    if args.input_row_size%args.patch_size!=0 or args.input_col_size%args.patch_size!=0:\n",
        "        print(\"args configuration error: input_row_size and input_col_size must be a multiple of patch_size\")\n",
        "        exit(1)\n",
        "    #output the args in a beautiful format\n",
        "    main(args)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb743152-c6d1-4108-9bdd-595a30da1545",
      "metadata": {},
      "source": [
        "3. Save this as inference/main_worker.py:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bcf1e26-9ad5-4999-8c5b-0e8e95a6bd61",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "from scipy.sparse import coo_matrix\n",
        "\n",
        "from utils.hic_coverage import calculate_coverage\n",
        "from data_processing.inference_dataset import Inference_Dataset\n",
        "from ops.io_utils import write_pickle,append_record\n",
        "from ops.mean_shift_merge import mean_shift_merge\n",
        "from ops.file_format_convert import pkl2others\n",
        "from utils.array2bigwig import array2bigwig\n",
        "from model.pos_embed import interpolate_pos_embed_inputsize\n",
        "\n",
        "\n",
        "def configure_dataset(args,input_pkl):\n",
        "    resolution = args.resolution\n",
        "    import torchvision.transforms as transforms\n",
        "    transform_input = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "    if args.task==3:\n",
        "        #resolution enhancement\n",
        "        fill_diagonal_zero=True\n",
        "        \n",
        "    else:\n",
        "        fill_diagonal_zero=False\n",
        "    if args.task==3:\n",
        "        #judge if it is a very deep sequencing data, if it is, set max_cutoff to None\n",
        "        coverage_perresolution = calculate_coverage(input_pkl)/resolution\n",
        "        if coverage_perresolution>1:\n",
        "            max_cutoff = None\n",
        "        else:\n",
        "            max_cutoff = 100\n",
        "    elif args.task==2:\n",
        "        #loop calling\n",
        "        max_cutoff = 1000\n",
        "    elif args.task==5:\n",
        "        #scHi-C enhancement\n",
        "        max_cutoff = 100\n",
        "    else:\n",
        "        max_cutoff = None\n",
        "    \n",
        "    if args.task==4:\n",
        "        #epigenomic assay prediction\n",
        "        locus_embedding = True\n",
        "    else:\n",
        "        locus_embedding = False\n",
        "        \n",
        "    bounding = args.bound\n",
        "    stride = args.stride\n",
        "    input_row_size = args.input_row_size\n",
        "    input_col_size = args.input_col_size\n",
        "    task = args.task\n",
        "    dataset = Inference_Dataset(data_path=input_pkl,   \n",
        "                            transform=transform_input,\n",
        "                            stride=stride,\n",
        "                            window_height= input_row_size,\n",
        "                            window_width = input_col_size,\n",
        "                            max_cutoff=max_cutoff,\n",
        "                            fill_diagonal_zero=fill_diagonal_zero,\n",
        "                            bounding=bounding,\n",
        "                            locus_embedding=locus_embedding,\n",
        "                            task=task)\n",
        "    sample_batch_size = args.batch_size\n",
        "    data_loader_test = torch.utils.data.DataLoader(\n",
        "        dataset,\n",
        "        batch_size=sample_batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=args.num_workers,\n",
        "        drop_last=False)\n",
        "    return data_loader_test\n",
        "\n",
        "def generate_loop(return_dict,threshold,output_bedpe,config_resolution):\n",
        "    with open(output_bedpe,'w') as wfile:\n",
        "        wfile.write(\"chr1\\tx1\\tx2\\tchr2\\ty1\\ty2\\n\")\n",
        "    for chrom in return_dict:\n",
        "        mean_array = return_dict[chrom]\n",
        "        if mean_array.shape[0]<=10000:\n",
        "            mean_array = mean_array.toarray()\n",
        "            try:\n",
        "                mean_loc_list = mean_shift_merge(mean_array,cutoff=threshold)\n",
        "            except:\n",
        "                mean_loc_list = []\n",
        "        else:\n",
        "            mean_loc_list = []\n",
        "            for i in range(0,mean_array.shape[0],10000):\n",
        "                cur_start = i\n",
        "                cur_end = min(i+10000,mean_array.shape[0])\n",
        "                select_index1 = (mean_array.row>=cur_start)&(mean_array.row<cur_end)\n",
        "                select_index2 = (mean_array.col>=cur_start)&(mean_array.col<cur_end)\n",
        "                select_index = select_index1&select_index2\n",
        "                cur_select_row = mean_array.row[select_index]-cur_start\n",
        "                cur_select_col = mean_array.col[select_index]-cur_start\n",
        "                cur_select_data = mean_array.data[select_index]\n",
        "                cur_size = cur_end-cur_start\n",
        "                cur_array = coo_matrix((cur_select_data,(cur_select_row,cur_select_col)),shape=(cur_size,cur_size))\n",
        "                cur_array = cur_array.toarray()\n",
        "                try:\n",
        "                    cur_loc_list = mean_shift_merge(cur_array,cutoff=threshold)\n",
        "                except:\n",
        "                   cur_loc_list = []\n",
        "                for loc in cur_loc_list:\n",
        "                    x,y = loc\n",
        "                    x+=cur_start\n",
        "                    y+=cur_start\n",
        "                    mean_loc_list.append([x,y])\n",
        "                print(i, \"detect length: mean\",len(cur_loc_list),\"total\",len(mean_loc_list))\n",
        "       \n",
        "        print(\"%s detect length: mean\"%chrom,len(mean_loc_list))\n",
        "        if \"_\" in chrom:\n",
        "            chrom = chrom.split(\"_\")[0]\n",
        "        append_record(output_bedpe,mean_loc_list,chrom,resolution=config_resolution)\n",
        "def main_worker(args, input_pkl):\n",
        "    resolution = args.resolution\n",
        "    #check model_path exists\n",
        "    model_path = os.path.abspath(args.model_path)\n",
        "    assert os.path.exists(model_path), \"model_path does not exist\"\n",
        "    output_dir = os.path.abspath(args.output)\n",
        "    dataloader = configure_dataset(args, input_pkl)\n",
        "    import model.Vision_Transformer_count as Vision_Transformer\n",
        "    #should be a dyanmic input model\n",
        "    patch_wise_size = (args.input_row_size//args.patch_size,args.input_col_size//args.patch_size)\n",
        "    vit_backbone = Vision_Transformer.__dict__[args.model](img_size=(args.input_row_size,args.input_col_size))\n",
        "    if args.task==6:\n",
        "        # embedding genration inference\n",
        "        # only load encoder weights\n",
        "        checkpoint = torch.load(model_path, map_location='cpu')\n",
        "        checkpoint_model = checkpoint['model']\n",
        "        state_dict = vit_backbone.state_dict()\n",
        "        for k in ['head.weight', 'head.bias']:\n",
        "            if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
        "                print(f\"Removing key {k} from pretrained checkpoint\")\n",
        "                del checkpoint_model[k]\n",
        "\n",
        "        # interpolate position embedding\n",
        "        #this can apply to most scenarios but not our condition\n",
        "        \n",
        "        interpolate_pos_embed_inputsize(vit_backbone, checkpoint_model,input_size=patch_wise_size,\n",
        "                                            use_decoder=False)\n",
        "        # load pre-trained model\n",
        "        msg = vit_backbone.load_state_dict(checkpoint_model, strict=False)\n",
        "        print(\"Loading pre-train encoder message:\",msg)\n",
        "    from model.Finetune_Model_Head import Finetune_Model_Head\n",
        "    model = Finetune_Model_Head(vit_backbone, task=args.task,\n",
        "                            decoder_embed_dim=512, decoder_depth=8, decoder_num_heads=16,\n",
        "                        mlp_ratio=4., norm_layer=nn.LayerNorm,pos_embed_size=patch_wise_size)\n",
        "    \n",
        "    \n",
        "    #load model weights\n",
        "    if args.task!=6:\n",
        "        checkpoint = torch.load(model_path, map_location='cpu')\n",
        "        if \"model\" in checkpoint:\n",
        "            checkpoint_model = checkpoint[\"model\"]\n",
        "        elif \"state_dict\" in checkpoint:\n",
        "            checkpoint_model = checkpoint[\"state_dict\"]\n",
        "        else:\n",
        "            checkpoint_model = checkpoint\n",
        "        msg = model.load_state_dict(checkpoint_model, strict=False)\n",
        "        print(\"Loading fine-tuned task-specific model message:\",msg)\n",
        "    else:\n",
        "        \n",
        "        checkpoint = torch.load(model_path, map_location='cpu')\n",
        "        checkpoint_model = checkpoint['model']\n",
        "        #loading pre-trained decoder\n",
        "        interpolate_pos_embed_inputsize(model, checkpoint['model'],\n",
        "                                        input_size=patch_wise_size,use_decoder=True)\n",
        "        msg = model.load_state_dict(checkpoint_model, strict=False)\n",
        "        print(\"Loading pre-train model decoder message:\",msg)\n",
        "\n",
        "    model = model.cuda()\n",
        "    model = nn.DataParallel(model, device_ids=None)\n",
        "    from inference.inference_worker import inference_worker\n",
        "    return_dict= inference_worker(model,dataloader,\n",
        "                                  log_dir=output_dir,\n",
        "                                  args=args)\n",
        "    if args.task==1:\n",
        "        output_path = os.path.join(output_dir,\"HiCFoundation_reproducibility_embedding.pkl\")\n",
        "        write_pickle(return_dict,output_path)\n",
        "        print(\"Reproducibility analysis finished!\")\n",
        "        print(\"The embedding results are saved to \",output_path)\n",
        "    elif args.task==2:\n",
        "        #0.9 is used for benchmark, but please choose the threshold based on your own data\n",
        "\n",
        "        threshold_list= [0.5,0.75,0.9]\n",
        "        for threshold in threshold_list:\n",
        "            output_bedpe = os.path.join(output_dir,\"HiCFoundation_loop_{}.bedpe\".format(threshold))\n",
        "            generate_loop(return_dict,threshold,output_bedpe,resolution)\n",
        "        print(\"Loop calling finished!\")\n",
        "        print(\"The loop calling results are saved to \",output_dir,\" with different thresholds in .bedpe format.\")\n",
        "    elif args.task==3:\n",
        "        #convert to hic format as final output\n",
        "        output_pkl = os.path.join(output_dir,\"HiCFoundation_enhanced.pkl\")\n",
        "        #revise the return dict key if it has \"_\", make to one chromosome\n",
        "        for key in list(return_dict.keys()):\n",
        "            if \"_\" in key:\n",
        "                key_list = key.split(\"_\")\n",
        "                return_dict[key_list[0]] = return_dict[key]\n",
        "                del return_dict[key]\n",
        "        write_pickle(return_dict,output_pkl)\n",
        "        input_file = os.path.abspath(args.input)\n",
        "        extention_name = input_file.split('.')[-1]\n",
        "        output_file = os.path.join(output_dir,\"HiCFoundation_enhanced.\"+extention_name)\n",
        "        pkl2others(output_pkl, output_file,resolution,args.genome_id)\n",
        "        if not os.path.exists(output_file):\n",
        "            print(\"Error: file conversion failed.\")\n",
        "            print(\"Resolution enhancement finished!\")\n",
        "            print(\"The final output is saved in .pkl format, please convert it to other formats manually.\")\n",
        "            print(\"The .pkl file is saved to \",output_pkl)\n",
        "    elif args.task==4:\n",
        "        #epigenomic assay prediction\n",
        "        output_path = os.path.join(output_dir,\"HiCFoundation_epigenomic_assay_prediction.pkl\")\n",
        "        write_pickle(return_dict,output_path)\n",
        "        #write to bigWig file\n",
        "        key_word_list=['CTCF','H3K4me3','H3K27ac','H3K27me3','ATAC-seq','DNase-seq']\n",
        "        for key_index,key_word in enumerate(key_word_list):\n",
        "            current_dict={}\n",
        "            for chrom in return_dict:\n",
        "                if \"_\" in chrom:\n",
        "                    chrom_key = chrom.split(\"_\")[0]\n",
        "                else:\n",
        "                    chrom_key = chrom\n",
        "                current_dict[chrom_key] = return_dict[chrom][key_index]\n",
        "            current_pkl = os.path.join(output_dir,\"HiCFoundation_epigenomic_assay_prediction_%s.pkl\"%key_word)\n",
        "            write_pickle(current_dict,current_pkl)\n",
        "            output_bigwig = os.path.join(output_dir,\"HiCFoundation_pred_%s.bigWig\"%key_word)\n",
        "            array2bigwig(current_pkl,output_bigwig,resolution=resolution)\n",
        "        print(\"Epigenomic assay prediction finished!\")\n",
        "        print(\"The prediction results are saved to \",output_dir,\" in .pkl and .bigWig format.\")\n",
        "\n",
        "    elif args.task==5:\n",
        "        #scHi-C enhancement\n",
        "        output_path = os.path.join(output_dir,\"HiCFoundation_sc_enhanced.pkl\")\n",
        "        write_pickle(return_dict,output_path)\n",
        "        input_file = os.path.abspath(args.input)\n",
        "        extention_name = input_file.split('.')[-1]\n",
        "        output_file = os.path.join(output_dir,\"HiCFoundation_sc_enhanced.\"+extention_name)\n",
        "        pkl2others(output_path, output_file,resolution,args.genome_id)\n",
        "        if not os.path.exists(output_file):\n",
        "            print(\"Error: file conversion failed.\")\n",
        "            print(\"scHi-C enhancement finished!\")\n",
        "            print(\"The final output is saved in .pkl format, please convert it to other formats manually.\")\n",
        "            print(\"The .pkl file is saved to \",output_path)\n",
        "    elif args.task==6:  \n",
        "        #embedding generation\n",
        "        output_path = os.path.join(output_dir,\"HiCFoundation_embedding.pkl\")\n",
        "        write_pickle(return_dict,output_path)\n",
        "        print(\"Hi-C embedding generation finished!\")\n",
        "        print(\"The embedding results are saved to \",output_path,\" in .pkl format.\")\n",
        "\n",
        "\n",
        "    print(\"Enjoy your HiCFoundation results!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f754cfa1-5994-4587-b242-9f0922420d0c",
      "metadata": {},
      "source": [
        "5. Save this as inference/load_model.py:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21c290e0-2fd3-4254-80bc-726164550bb6",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def load_model(model_path,input_row_size,input_col_size, task=6):\n",
        "    \"\"\"\n",
        "    Load a model from a file.\n",
        "\n",
        "    Args:\n",
        "        model_path (str): The path to the model file.\n",
        "        input_row_size (int): The number of rows in the input matrix.\n",
        "        input_col_size (int): The number of columns in the input matrix.\n",
        "\n",
        "    Returns:\n",
        "        model: The loaded model.\n",
        "\n",
        "    Notes:\n",
        "        task 0: fine-tuning setting\n",
        "        task 1: reproducibility analysis\n",
        "        task 2: loop calling\n",
        "        task 3: resolution enhancement\n",
        "        task 4: epigenomic assay prediction\n",
        "        task 5: scHi-C enhancement\n",
        "        task 6: embedding analysis\n",
        "    \"\"\"\n",
        "    import torch\n",
        "    import model.Vision_Transformer_count as Vision_Transformer\n",
        "    from model.pos_embed import interpolate_pos_embed_inputsize\n",
        "    import torch.nn as nn\n",
        "\n",
        "    model_name=\"vit_large_patch16\"\n",
        "    patch_size=16\n",
        "\n",
        "    patch_wise_size = (input_row_size//patch_size, input_col_size//patch_size)\n",
        "    vit_backbone = Vision_Transformer.__dict__[model_name](img_size=(input_row_size,input_col_size))\n",
        "    checkpoint = torch.load(model_path, map_location='cpu')\n",
        "    checkpoint_model = checkpoint['model']\n",
        "    state_dict = vit_backbone.state_dict()\n",
        "    for k in ['head.weight', 'head.bias']:\n",
        "        if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
        "            print(f\"Removing key {k} from pretrained checkpoint\")\n",
        "            del checkpoint_model[k]\n",
        "    interpolate_pos_embed_inputsize(vit_backbone, checkpoint_model,input_size=patch_wise_size,\n",
        "                                            use_decoder=False)\n",
        "    # load pre-trained model\n",
        "    msg = vit_backbone.load_state_dict(checkpoint_model, strict=False)\n",
        "    print(\"Loading pre-train encoder message!\")\n",
        "\n",
        "    from model.Finetune_Model_Head import Finetune_Model_Head\n",
        "    model = Finetune_Model_Head(vit_backbone, task=task,\n",
        "                            decoder_embed_dim=512, decoder_depth=8, decoder_num_heads=16,\n",
        "                        mlp_ratio=4., norm_layer=nn.LayerNorm,pos_embed_size=patch_wise_size)\n",
        "    checkpoint = torch.load(model_path, map_location='cpu')\n",
        "    checkpoint_model = checkpoint['model']\n",
        "    #loading pre-trained decoder\n",
        "    interpolate_pos_embed_inputsize(model, checkpoint['model'],\n",
        "                                    input_size=patch_wise_size,use_decoder=True)\n",
        "    msg = model.load_state_dict(checkpoint_model, strict=False)\n",
        "    print(\"Loading pre-train model decoder!\")\n",
        "    return model # return the loaded model\n",
        "\n",
        "def to_cuda(x):\n",
        "    \"\"\"\n",
        "    Move a tensor to the GPU.\n",
        "\n",
        "    Args:\n",
        "        x (torch.Tensor): The tensor to move to the GPU.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The tensor on the GPU.\n",
        "    \"\"\"\n",
        "    import torch\n",
        "    if x is not None:\n",
        "        #if it is float or int, change to tensor\n",
        "        if type(x) is int or type(x) is float:\n",
        "            x = torch.tensor(x)\n",
        "        return x.cuda()\n",
        "    else:\n",
        "        return None\n",
        "    \n",
        "def to_float(x):\n",
        "    \"\"\"\n",
        "    Convert a tensor to float.\n",
        "\n",
        "    Args:\n",
        "        x (torch.Tensor): The tensor to convert to float.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The tensor as float.\n",
        "    \"\"\"\n",
        "    import torch\n",
        "    if x is not None:\n",
        "        return x.float()\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def convert_rgb(data_log,max_value):\n",
        "    import torch\n",
        "    if len(data_log.shape)==2:\n",
        "        data_log = data_log[None,:,:]\n",
        "    data_red = torch.ones(data_log.shape)\n",
        "    data_log1 = (max_value-data_log)/max_value\n",
        "    data_rgb = torch.cat([data_red,data_log1,data_log1],dim=0)\n",
        "    return data_rgb\n",
        "\n",
        "def format_input(input):\n",
        "    \"\"\"\n",
        "    Format the input for the model.\n",
        "\n",
        "    Args:\n",
        "        input (torch.Tensor): The input tensor.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The formatted input tensor.\n",
        "    \"\"\"\n",
        "    import torch\n",
        "    import torchvision.transforms as transforms\n",
        "    transform_input = transforms.Compose([\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "    \n",
        "    input = torch.nan_to_num(input)\n",
        "    max_value = torch.max(input)\n",
        "    input = torch.log10(input+1)\n",
        "    max_value = torch.log10(max_value+1)\n",
        "    input = convert_rgb(input,max_value)\n",
        "    \n",
        "    input = transform_input(input)\n",
        "    return input"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f810375-c1ee-430e-8f88-4fbe0ff71f2f",
      "metadata": {},
      "source": [
        "6. Save this as inference/inference_worker.py:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e7188c3-4de7-44bc-b297-2e2fd99c0882",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import sys\n",
        "import numpy as np\n",
        "from typing import Iterable\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "from ops.Logger import MetricLogger,SmoothedValue\n",
        "import os\n",
        "from collections import defaultdict\n",
        "from ops.sparse_ops import array_to_coo\n",
        "from scipy.sparse import coo_matrix,triu\n",
        "def inference_worker(model,data_loader,log_dir=None,args=None):\n",
        "    \"\"\"\n",
        "    model: model for inference\n",
        "    data_loader: data loader for inference\n",
        "    log_dir: log directory for inference\n",
        "    args: arguments for inference\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    config_resolution = args.resolution\n",
        "    metric_logger = MetricLogger(delimiter=\"  \")\n",
        "    header = 'Inference: '\n",
        "    print_freq = args.print_freq\n",
        "    print(\"number of iterations: \",len(data_loader))\n",
        "    num_iter = len(data_loader)\n",
        "    dataset_shape_dict = data_loader.dataset.dataset_shape\n",
        "    infer_task = args.task\n",
        "    if infer_task==1:\n",
        "        output_dict=defaultdict(list)\n",
        "    elif infer_task==2 or infer_task==3 or infer_task==5:\n",
        "        output_dict={}\n",
        "        for chrom in dataset_shape_dict:\n",
        "            output_dict[chrom] = {\"row_record\":[],\"col_record\":[],\"value_record\":[],\"count_record\":[]}\n",
        "    elif infer_task==4:\n",
        "        #epigenomic assay prediction\n",
        "        num_track = 6\n",
        "        output_dict={}\n",
        "        for chrom in dataset_shape_dict:\n",
        "            current_shape = dataset_shape_dict[chrom]\n",
        "            current_length = current_shape[0]\n",
        "            mean_array = np.zeros([num_track,current_length])\n",
        "            count_array = np.zeros([num_track,current_length])\n",
        "            output_dict[chrom] = {\"mean\":mean_array,\"count\":count_array}\n",
        "    elif infer_task==6:\n",
        "        output_dict={\"submat_embedding\":defaultdict(list),\"patch_embedding\":defaultdict(list)}\n",
        "\n",
        "    if infer_task==3:\n",
        "        #resolution enhancement\n",
        "        cutoff= 1000\n",
        "        cutoff = torch.tensor(cutoff).float().cuda()\n",
        "        log_cutoff = torch.log10(cutoff+1).cuda()\n",
        "    if infer_task==5:\n",
        "        #scHi-C enhancement\n",
        "        cutoff= 1000\n",
        "        log_cutoff = np.log10(cutoff+1)\n",
        "        output_dict={}\n",
        "        for chrom in dataset_shape_dict:\n",
        "            current_shape = dataset_shape_dict[chrom]\n",
        "            current_length = current_shape[0]\n",
        "            mean_array = np.zeros(current_shape)\n",
        "            count_array = np.zeros(current_shape)\n",
        "            output_dict[chrom] = {\"mean\":mean_array,\"count\":count_array}\n",
        "    for data_iter_step, data in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n",
        "        input,total_count,indexes = data\n",
        "        input = input.cuda()\n",
        "        input = input.float()\n",
        "        total_count = total_count.cuda()\n",
        "        total_count = total_count.float()\n",
        "        with torch.no_grad():\n",
        "            output = model(input,total_count) \n",
        "            # fixme: loop, and epigenomic assay prediction did not take count in benchmark, I think this will not impact performance, will check later. If yes, will revise it to model(input)\n",
        "        if infer_task==1:\n",
        "            #reproducibility analysis\n",
        "            pass\n",
        "        elif infer_task==2:\n",
        "            #loop calling\n",
        "            output= torch.sigmoid(output)\n",
        "        elif infer_task==3:\n",
        "            #resolution enhancement\n",
        "            output = output*log_cutoff\n",
        "            output = torch.pow(10,output)-1\n",
        "            output = torch.clamp(output,min=0)\n",
        "\n",
        "        elif infer_task==6:\n",
        "            #get the specified encoder/decoder layer's output\n",
        "            output = output[args.embed_depth]\n",
        "\n",
        "\n",
        "        # elif infer_task==5:\n",
        "        #     #scHi-C enhancement\n",
        "        #     output = output*log_cutoff\n",
        "        #     output = torch.pow(10,output)-1\n",
        "        #     output = torch.round(output)-2\n",
        "        #     output = torch.clamp(output,min=0)\n",
        "\n",
        "        output = output.detach().cpu().numpy()\n",
        "        input = input.detach().cpu().numpy()\n",
        "        chrs, row_starts, col_starts = indexes\n",
        "        for i in range(len(output)):\n",
        "            chr = chrs[i]\n",
        "            row_start = row_starts[i]\n",
        "            col_start = col_starts[i]\n",
        "            row_start = int(row_start)\n",
        "            col_start = int(col_start)\n",
        "            row_start = max(0,row_start)\n",
        "            col_start = max(0,col_start)\n",
        "            current_shape = dataset_shape_dict[chr]\n",
        "            row_end = min(row_start+args.input_row_size,current_shape[0])\n",
        "            col_end = min(col_start+args.input_col_size,current_shape[1])\n",
        "            current_input = input[i]\n",
        "            #input_count = np.sum(current_input)\n",
        "            #ignore empty matrix\n",
        "            if np.isnan(np.sum(current_input)):\n",
        "                print(\"empty matrix:\",chr,row_start,col_start)\n",
        "                continue\n",
        "\n",
        "            # # may be not necessary, will check if error happens\n",
        "            # if input_count<=len(current_input):\n",
        "            #     #skip super low read count matrix\n",
        "            #     #that's to say, <1 read per 10 kb, samller than 0.3M total read for human\n",
        "            #     continue\n",
        "            cur_output = output[i]\n",
        "            if infer_task==1:\n",
        "                match_key = f\"{chr}:{row_start*config_resolution},{col_start*config_resolution}\"\n",
        "                output_dict[match_key] = cur_output\n",
        "            elif infer_task==2 or infer_task==3:\n",
        "                #loop calling, resolution enhancement\n",
        "                cur_output = cur_output[:row_end-row_start,:col_end-col_start]\n",
        "                cur_output = array_to_coo(cur_output)\n",
        "                output_dict[chr][\"row_record\"].append(cur_output.row+row_start)\n",
        "                output_dict[chr][\"col_record\"].append(cur_output.col+col_start)\n",
        "                output_dict[chr][\"value_record\"].append(cur_output.data)\n",
        "                output_dict[chr][\"count_record\"].append([1]*len(cur_output.data))\n",
        "            elif infer_task==4:\n",
        "                #epigenomic assay prediction\n",
        "                cur_output = cur_output[:, :row_end-row_start]\n",
        "                output_dict[chr]['mean'][:, row_start:row_end] += cur_output\n",
        "                output_dict[chr]['count'][:, row_start:row_end] += 1\n",
        "\n",
        "            elif infer_task==6:\n",
        "                refer_row = row_start\n",
        "                refer_col = col_start\n",
        "                real_row_start = max(0,refer_row-args.input_row_size//2)\n",
        "                real_col_start = max(0,refer_col-args.input_col_size//2)\n",
        "                real_row_end = min(current_shape[0],refer_row+args.input_row_size//2)\n",
        "                real_col_end = min(current_shape[1],refer_col+args.input_col_size//2)\n",
        "                patch_row_range = (real_row_end-real_row_start)//args.patch_size\n",
        "                patch_col_range = (real_col_end-real_col_start)//args.patch_size\n",
        "                # cur_output = cur_output[:patch_row_range,:patch_col_range]\n",
        "                # we can let the patch embedding choice.\n",
        "                if args.patch_embedding:\n",
        "                    for row_index in range(real_row_start,real_row_end, args.patch_size):\n",
        "                        for col_index in range(real_col_start,real_col_end,args.patch_size):\n",
        "                            row_index = int(row_index)\n",
        "                            col_index = int(col_index)\n",
        "                            patch_row_index = (row_index-real_row_start)//args.patch_size\n",
        "                            patch_col_index = (col_index-real_col_start)//args.patch_size\n",
        "                            cur_patch_embedding = cur_output[patch_row_index,patch_col_index]\n",
        "                            middle_row = row_index+args.patch_size//2\n",
        "                            middle_col = col_index+args.patch_size//2\n",
        "                            search_key = f\"{chr}:{middle_row*config_resolution},{middle_col*config_resolution}\"\n",
        "                            output_dict[\"patch_embedding\"][search_key].append(cur_patch_embedding)\n",
        "                            \n",
        "                search_key = f\"{chr}:{refer_row*config_resolution},{refer_col*config_resolution}\"\n",
        "                #average embedding\n",
        "                all_embedding = cur_output.reshape(-1,cur_output.shape[-1])\n",
        "                all_embedding = np.mean(all_embedding,axis=0)\n",
        "                output_dict[\"submat_embedding\"][search_key].append(all_embedding)\n",
        "\n",
        "\n",
        "            elif infer_task == 5:\n",
        "                #scHi-C enhancement\n",
        "                if current_shape[0] < args.input_row_size or current_shape[1] < args.input_col_size:\n",
        "                    #remove padding regions\n",
        "                    left_up_pad_size = (args.input_row_size - current_shape[0]) // 2\n",
        "                    right_down_pad_size = args.input_row_size - current_shape[0] - left_up_pad_size\n",
        "                    left_up_pad_size_col = (args.input_col_size - current_shape[1]) // 2\n",
        "                    right_down_pad_size_col = args.input_col_size - current_shape[1] - left_up_pad_size_col\n",
        "                    cur_output = cur_output[left_up_pad_size:-right_down_pad_size, left_up_pad_size_col:-right_down_pad_size_col]\n",
        "                    output_dict[chr]['mean'] += cur_output\n",
        "                    output_dict[chr]['count'] += 1\n",
        "                else:\n",
        "                    output_dict[chr]['mean'][row_start:row_start+args.input_row_size, col_start:col_start+args.input_col_size] += cur_output\n",
        "                    output_dict[chr]['count'][row_start:row_start+args.input_row_size, col_start:col_start+args.input_col_size] += 1\n",
        "                # cur_output = array_to_coo(cur_output)\n",
        "                # output_dict[chr][\"row_record\"].append(cur_output.row+row_start)\n",
        "                # output_dict[chr][\"col_record\"].append(cur_output.col+col_start)\n",
        "                # output_dict[chr][\"value_record\"].append(cur_output.data)\n",
        "                # output_dict[chr][\"count_record\"].append([1]*len(cur_output.data))\n",
        "\n",
        "\n",
        "    \n",
        "    if infer_task==1:\n",
        "        return output_dict\n",
        "    elif infer_task==2 or infer_task==3:\n",
        "        final_dict={}\n",
        "        for chrom in output_dict:\n",
        "            row_record = np.concatenate(output_dict[chrom][\"row_record\"])\n",
        "            col_record = np.concatenate(output_dict[chrom][\"col_record\"])\n",
        "            value_record = np.concatenate(output_dict[chrom][\"value_record\"])\n",
        "            count_record = np.concatenate(output_dict[chrom][\"count_record\"])\n",
        "            combine_row=np.concatenate([row_record,col_record])\n",
        "            combine_col=np.concatenate([col_record,row_record])\n",
        "            combine_value=np.concatenate([value_record,value_record])\n",
        "            combine_count=np.concatenate([count_record,count_record])\n",
        "            prediction_sym = coo_matrix((combine_value, (combine_row, combine_col)), shape=dataset_shape_dict[chrom])\n",
        "            count_sym = coo_matrix((combine_count, (combine_row, combine_col)), shape=dataset_shape_dict[chrom])\n",
        "            \n",
        "            prediction_sym.sum_duplicates()\n",
        "            count_sym.sum_duplicates()\n",
        "            prediction_sym.data = prediction_sym.data/count_sym.data\n",
        "            #remove very small prediction to save time\n",
        "            select_index = prediction_sym.data>0.01\n",
        "            prediction_sym.data = prediction_sym.data[select_index]\n",
        "            prediction_sym.row = prediction_sym.row[select_index]\n",
        "            prediction_sym.col = prediction_sym.col[select_index]\n",
        "            print(\"finish summarize %s prediction\"%chrom,prediction_sym.nnz)\n",
        "            final_dict[chrom] = triu(prediction_sym,0)\n",
        "        return final_dict\n",
        "    elif infer_task==4:\n",
        "        #epigenomic assay prediction\n",
        "        return_dict={}\n",
        "        for chrom in dataset_shape_dict:\n",
        "            count_array=output_dict[chrom]['count']\n",
        "            mean_array=output_dict[chrom]['mean']\n",
        "            count_array =np.maximum(count_array,1)\n",
        "            mean_array = mean_array/count_array\n",
        "            mean_array = np.nan_to_num(mean_array)\n",
        "            return_dict[chrom] = mean_array\n",
        "        return return_dict\n",
        "    elif infer_task == 5:\n",
        "        return_dict={}\n",
        "        for chrom in dataset_shape_dict:\n",
        "            count_array=output_dict[chrom]['count']\n",
        "            mean_array=output_dict[chrom]['mean']\n",
        "            count_array =np.maximum(count_array,1)\n",
        "            mean_array = (mean_array + mean_array.T)/2\n",
        "            mean_array = mean_array/count_array\n",
        "            mean_array = np.nan_to_num(mean_array)\n",
        "            mean_array = mean_array*log_cutoff\n",
        "            mean_array = np.power(10, mean_array) - 1\n",
        "            mean_array = np.round(mean_array) - 2\n",
        "            mean_array = np.clip(mean_array, 0, np.max(mean_array))\n",
        "            return_dict[chrom] = np.triu(mean_array)\n",
        "        return return_dict\n",
        "\n",
        "    elif infer_task==6:\n",
        "        #embedding generation\n",
        "        return_dict={\"submat_embedding\":{},\"patch_embedding\":{},\"chromo_embedding\":{},\"genome_embedding\":{}}\n",
        "\n",
        "        #read patch embedding in output_dict, average the same location embedding\n",
        "        for key in output_dict[\"patch_embedding\"]:\n",
        "            cur_embedding = output_dict[\"patch_embedding\"][key]\n",
        "            cur_embedding = np.stack(cur_embedding,axis=0)\n",
        "            cur_embedding = np.mean(cur_embedding,axis=0)\n",
        "            return_dict[\"patch_embedding\"][key] = cur_embedding\n",
        "        \n",
        "        #read submat embedding in output_dict, average the same location embedding\n",
        "        chrom_embedding = defaultdict(list)\n",
        "        for key in output_dict[\"submat_embedding\"]:\n",
        "            cur_embedding = output_dict[\"submat_embedding\"][key]\n",
        "            cur_embedding = np.stack(cur_embedding,axis=0)\n",
        "            cur_embedding = np.mean(cur_embedding,axis=0)\n",
        "            return_dict[\"submat_embedding\"][key] = cur_embedding\n",
        "            chrom = key.split(\":\")[0]\n",
        "            chrom_embedding[chrom].append(cur_embedding)\n",
        "        \n",
        "        #get average chromo embedding\n",
        "        for chrom in chrom_embedding:\n",
        "            cur_embedding = chrom_embedding[chrom]\n",
        "            cur_embedding = np.stack(cur_embedding,axis=0)\n",
        "            cur_embedding = np.mean(cur_embedding,axis=0)\n",
        "            return_dict[\"chromo_embedding\"][chrom] = cur_embedding\n",
        "        #get average genome embedding\n",
        "        all_embedding = list(return_dict[\"chromo_embedding\"].values())\n",
        "        all_embedding = np.stack(all_embedding,axis=0)\n",
        "        all_embedding = np.mean(all_embedding,axis=0)\n",
        "        return_dict[\"genome_embedding\"] = all_embedding\n",
        "        return return_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1e38fee-a655-46c1-a3c1-3f440b4bd48b",
      "metadata": {},
      "source": [
        "7. Run inference on new Hi-C data (task 3 is for resolution enhancement):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "639aeb6c-e927-4402-8a25-3026e5035e64",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "python inference.py --batch_size 1 \\\n",
        "    --input B1-GSM4705442_cmt2cmt3.hic \\\n",
        "    --resolution 10000 \\\n",
        "    --task 3 \\\n",
        "    --input_row_size 224 --input_col_size 224 \\\n",
        "    --stride 32 --bound 0 \\\n",
        "    --num_workers 1 \\\n",
        "    --model hicfoundation_finetune/model/model_best.pth.tar \\\n",
        "    --model_path hicfoundation_finetune/model/model_best.pth.tar \\\n",
        "    --output B1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4120b121-4f10-4ba7-801d-ea9a118245f5",
      "metadata": {},
      "source": [
        "And Done! The directory B1 should have the enhanced files in both .hic and .pkl format"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
